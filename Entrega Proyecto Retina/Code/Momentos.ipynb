{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>...</th>\n",
       "      <th>V77</th>\n",
       "      <th>V78</th>\n",
       "      <th>V79</th>\n",
       "      <th>V80</th>\n",
       "      <th>V81</th>\n",
       "      <th>V82</th>\n",
       "      <th>V83</th>\n",
       "      <th>V84</th>\n",
       "      <th>V85</th>\n",
       "      <th>V86</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1.200000e+03</td>\n",
       "      <td>1.200000e+03</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>600.500000</td>\n",
       "      <td>0.950840</td>\n",
       "      <td>0.776060</td>\n",
       "      <td>0.877859</td>\n",
       "      <td>0.524325</td>\n",
       "      <td>0.248244</td>\n",
       "      <td>0.082523</td>\n",
       "      <td>0.069509</td>\n",
       "      <td>0.496674</td>\n",
       "      <td>0.741113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111520</td>\n",
       "      <td>1.286498e-03</td>\n",
       "      <td>1.848060e-05</td>\n",
       "      <td>0.061520</td>\n",
       "      <td>0.075755</td>\n",
       "      <td>0.319202</td>\n",
       "      <td>0.203188</td>\n",
       "      <td>0.017005</td>\n",
       "      <td>0.387696</td>\n",
       "      <td>0.111520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>346.554469</td>\n",
       "      <td>0.027192</td>\n",
       "      <td>0.115970</td>\n",
       "      <td>0.087197</td>\n",
       "      <td>0.112408</td>\n",
       "      <td>0.066115</td>\n",
       "      <td>0.039561</td>\n",
       "      <td>0.050328</td>\n",
       "      <td>0.079411</td>\n",
       "      <td>0.080106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147778</td>\n",
       "      <td>4.155548e-03</td>\n",
       "      <td>1.923041e-04</td>\n",
       "      <td>0.045066</td>\n",
       "      <td>0.052003</td>\n",
       "      <td>0.136775</td>\n",
       "      <td>0.009377</td>\n",
       "      <td>0.019344</td>\n",
       "      <td>0.123989</td>\n",
       "      <td>0.147778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.797251</td>\n",
       "      <td>-0.342768</td>\n",
       "      <td>-0.198698</td>\n",
       "      <td>0.254143</td>\n",
       "      <td>0.100968</td>\n",
       "      <td>0.005312</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.301341</td>\n",
       "      <td>0.421211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>4.995792e-07</td>\n",
       "      <td>6.388314e-13</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.007707</td>\n",
       "      <td>0.008779</td>\n",
       "      <td>0.175191</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.099659</td>\n",
       "      <td>0.000454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>300.750000</td>\n",
       "      <td>0.938737</td>\n",
       "      <td>0.718571</td>\n",
       "      <td>0.847775</td>\n",
       "      <td>0.439657</td>\n",
       "      <td>0.195347</td>\n",
       "      <td>0.054824</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>0.438338</td>\n",
       "      <td>0.687385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015323</td>\n",
       "      <td>1.143614e-04</td>\n",
       "      <td>7.201021e-08</td>\n",
       "      <td>0.000923</td>\n",
       "      <td>0.035395</td>\n",
       "      <td>0.219083</td>\n",
       "      <td>0.199933</td>\n",
       "      <td>0.001872</td>\n",
       "      <td>0.292957</td>\n",
       "      <td>0.015323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>600.500000</td>\n",
       "      <td>0.957155</td>\n",
       "      <td>0.796020</td>\n",
       "      <td>0.897847</td>\n",
       "      <td>0.520438</td>\n",
       "      <td>0.242748</td>\n",
       "      <td>0.075433</td>\n",
       "      <td>0.089516</td>\n",
       "      <td>0.486904</td>\n",
       "      <td>0.753088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048836</td>\n",
       "      <td>4.485758e-04</td>\n",
       "      <td>6.775493e-07</td>\n",
       "      <td>0.080717</td>\n",
       "      <td>0.060242</td>\n",
       "      <td>0.310477</td>\n",
       "      <td>0.201102</td>\n",
       "      <td>0.005976</td>\n",
       "      <td>0.375698</td>\n",
       "      <td>0.048836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>900.250000</td>\n",
       "      <td>0.970753</td>\n",
       "      <td>0.854023</td>\n",
       "      <td>0.931466</td>\n",
       "      <td>0.605814</td>\n",
       "      <td>0.301663</td>\n",
       "      <td>0.101091</td>\n",
       "      <td>0.111467</td>\n",
       "      <td>0.543165</td>\n",
       "      <td>0.805550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143090</td>\n",
       "      <td>1.374960e-03</td>\n",
       "      <td>4.356554e-06</td>\n",
       "      <td>0.097506</td>\n",
       "      <td>0.103103</td>\n",
       "      <td>0.407632</td>\n",
       "      <td>0.203349</td>\n",
       "      <td>0.035148</td>\n",
       "      <td>0.467770</td>\n",
       "      <td>0.143090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1200.000000</td>\n",
       "      <td>0.990577</td>\n",
       "      <td>0.978692</td>\n",
       "      <td>0.992599</td>\n",
       "      <td>0.785803</td>\n",
       "      <td>0.543628</td>\n",
       "      <td>0.304764</td>\n",
       "      <td>0.187166</td>\n",
       "      <td>0.776476</td>\n",
       "      <td>0.890036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.772722</td>\n",
       "      <td>8.433157e-02</td>\n",
       "      <td>6.455221e-03</td>\n",
       "      <td>0.145922</td>\n",
       "      <td>0.242209</td>\n",
       "      <td>0.786896</td>\n",
       "      <td>0.346866</td>\n",
       "      <td>0.057499</td>\n",
       "      <td>0.888692</td>\n",
       "      <td>0.772722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0           V4           V5           V6           V7  \\\n",
       "count  1200.000000  1200.000000  1200.000000  1200.000000  1200.000000   \n",
       "mean    600.500000     0.950840     0.776060     0.877859     0.524325   \n",
       "std     346.554469     0.027192     0.115970     0.087197     0.112408   \n",
       "min       1.000000     0.797251    -0.342768    -0.198698     0.254143   \n",
       "25%     300.750000     0.938737     0.718571     0.847775     0.439657   \n",
       "50%     600.500000     0.957155     0.796020     0.897847     0.520438   \n",
       "75%     900.250000     0.970753     0.854023     0.931466     0.605814   \n",
       "max    1200.000000     0.990577     0.978692     0.992599     0.785803   \n",
       "\n",
       "                V8           V9          V10          V11          V12  \\\n",
       "count  1200.000000  1200.000000  1200.000000  1200.000000  1200.000000   \n",
       "mean      0.248244     0.082523     0.069509     0.496674     0.741113   \n",
       "std       0.066115     0.039561     0.050328     0.079411     0.080106   \n",
       "min       0.100968     0.005312     0.000835     0.301341     0.421211   \n",
       "25%       0.195347     0.054824     0.001908     0.438338     0.687385   \n",
       "50%       0.242748     0.075433     0.089516     0.486904     0.753088   \n",
       "75%       0.301663     0.101091     0.111467     0.543165     0.805550   \n",
       "max       0.543628     0.304764     0.187166     0.776476     0.890036   \n",
       "\n",
       "          ...               V77           V78           V79          V80  \\\n",
       "count     ...       1200.000000  1.200000e+03  1.200000e+03  1200.000000   \n",
       "mean      ...          0.111520  1.286498e-03  1.848060e-05     0.061520   \n",
       "std       ...          0.147778  4.155548e-03  1.923041e-04     0.045066   \n",
       "min       ...          0.000454  4.995792e-07  6.388314e-13     0.000228   \n",
       "25%       ...          0.015323  1.143614e-04  7.201021e-08     0.000923   \n",
       "50%       ...          0.048836  4.485758e-04  6.775493e-07     0.080717   \n",
       "75%       ...          0.143090  1.374960e-03  4.356554e-06     0.097506   \n",
       "max       ...          0.772722  8.433157e-02  6.455221e-03     0.145922   \n",
       "\n",
       "               V81          V82          V83          V84          V85  \\\n",
       "count  1200.000000  1200.000000  1200.000000  1200.000000  1200.000000   \n",
       "mean      0.075755     0.319202     0.203188     0.017005     0.387696   \n",
       "std       0.052003     0.136775     0.009377     0.019344     0.123989   \n",
       "min       0.007707     0.008779     0.175191     0.000560     0.099659   \n",
       "25%       0.035395     0.219083     0.199933     0.001872     0.292957   \n",
       "50%       0.060242     0.310477     0.201102     0.005976     0.375698   \n",
       "75%       0.103103     0.407632     0.203349     0.035148     0.467770   \n",
       "max       0.242209     0.786896     0.346866     0.057499     0.888692   \n",
       "\n",
       "               V86  \n",
       "count  1200.000000  \n",
       "mean      0.111520  \n",
       "std       0.147778  \n",
       "min       0.000454  \n",
       "25%       0.015323  \n",
       "50%       0.048836  \n",
       "75%       0.143090  \n",
       "max       0.772722  \n",
       "\n",
       "[8 rows x 84 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "################\n",
    "#m = 4\n",
    "#nombres = ['RGB.Laplaciano'+str(i+1) for i in range(m)]+['RGB.Sobelx'+str(i+1) for i in range(m)]+['RGB.Sobely'+str(i+1) for i in range(m)]+['RGB.Canny'+str(i+1) for i in range(m)]+['R'  +str(i+1) for i in range(m)]+['G' +str(i+1) for i in range(m)]+['B' +str(i+1) for i in range(m)]+['R.Espacial'+str(i+1) for i in range(m)]+['G.Espacial'+str(i+1) for i in range(m)]+['B.Espacial'+str(i+1) for i in range(m)]+['HSV.Laplaciano'+str(i+1) for i in range(m)]+['HSV.Sobelx'+str(i+1) for i in range(m)]+['HSV.Sobely'+str(i+1) for i in range(m)]+['HSV.Canny'+str(i+1) for i in range(m)]+['H'+str(i+1) for i in range(m)]+['S'+str(i+1) for i in range(m)]+['V'+str(i+1) for i in range(m)]+['H.Espacial'+str(i+1) for i in range(m)]+['S.Espacial' +str(i+1) for i in range(m)]+['V.Espacial' +str(i+1) for i in range(m)]+['Eigen' +str(i+1) for i in range(3)] +['BGR.Laplaciano'+str(i+1) for i in range(m)]+['BGR.Sobelx'+str(i+1) for i in range(m)]+['BGR.Sobely'+str(i+1) for i in range(m)]+['BGR.Canny'+str(i+1) for i in range(m)]+['PC1.'+str(i+1) for i in range(m)]+['PC2.'+str(i+1) for i in range(m)]+['PC3.'+str(i+1) for i in range(m)]+['PC1.Espacial'+str(i+1) for i in range(m)]+['PC2.Espacial'+str(i+1) for i in range(m)]+['PC3.Espacial'+str(i+1) for i in range(m)]\n",
    "#y = pd.read_csv('C:\\\\Users\\\\fou-f\\\\Desktop\\\\CD2EDUARDOFOO\\\\Retina\\\\Code\\\\metadata.csv')\n",
    "datos = pd.read_csv('C:\\\\Users\\\\fou-f\\\\Desktop\\\\CD2EDUARDOFOO\\\\Retina\\\\Resultados\\\\momentos.csv')\n",
    "y = np.array(datos['y'])\n",
    "del  datos['y'] \n",
    "del datos['V1']\n",
    "del datos['V2']\n",
    "del datos['V3']\n",
    "####################\n",
    "datos.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datos.columns =nombres\n",
    "train, test, y_train, y_test = train_test_split(datos, y, test_size=0.3, random_state=0) # es importante este detalle para que todos tengamos el mismo resultado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def grid_search():\n",
    "    pipeline1  = Pipeline([ ('classifier', RandomForestClassifier(random_state = 42))])\n",
    "    #pipeline2 = Pipeline(( ('clf', KNeighborsClassifier()), ))\n",
    "    #pipeline3 = Pipeline(( ('clf', SVC()), ))\n",
    "    pipeline4 = Pipeline((('logistic', LogisticRegression()),))\n",
    "    parameters1 = {\n",
    "    'classifier__n_estimators': [i+1 for i in range(round(len(train))) if i % 20 == 1] }\n",
    "\n",
    "    #parameters2 = {\n",
    "    #'clf__n_neighbors': [ i+1 for i in range(round(len(train)**.5)) if i% 30 == 1]}\n",
    "\n",
    "    #parameters3 = {\n",
    "    #'clf__C': [0.01, 0.1, .4, 9.0],\n",
    "    #'clf__kernel': ['rbf'],\n",
    "    #'clf__gamma': [0.01, 0.1, 1.0]\n",
    "    #}\n",
    "    parameters4= { 'logistic__C' :  [ np.exp(i) for i in  range(-4, 1000, 10) ]}\n",
    "\n",
    "    #pars = [parameters1, parameters2, parameters3, parameters4]\n",
    "    #pips = [pipeline1, pipeline2, pipeline3, pipeline4]\n",
    "    pars = [parameters1, parameters4]\n",
    "    pips = [pipeline1, pipeline4]\n",
    "\n",
    "\n",
    "    print (\"starting Gridsearch\")\n",
    "    for i in range(len(pars)):\n",
    "        gs = GridSearchCV(pips[i], pars[i], verbose=1, refit=True, cv=5)\n",
    "        gs = gs.fit(np.matrix(train), y_train)\n",
    "        print (\"finished Gridsearch\")\n",
    "        print (gs.best_score_)\n",
    "    return(gs)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting Gridsearch\n",
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 210 out of 210 | elapsed:  4.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished Gridsearch\n",
      "0.6988095238095238\n",
      "Fitting 5 folds for each of 101 candidates, totalling 505 fits\n"
     ]
    }
   ],
   "source": [
    "modelo =  grid_search()\n",
    "print(modelo.best_params_)\n",
    "print(modelo.best_estimator_)\n",
    "y_hat = modelo.predict(np.matrix(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test, y_hat))\n",
    "print(confusion_matrix(y_test, y_hat))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_hat).ravel() \n",
    "tn, fp, fn, tp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
